# 요약

**molecular generative model**

key idea : estimate the distribution of molecules → sample unseen molecules with target(desired) properties

de novo molecules design에 사용

**VAE** : latent variables(posterior) distribution의 insufficiently flexible prior로 approximating 문제(low validity). 

- prior distribution - predifined prior / surrogate distribution / prior(ex : multivariate Gaussian distribution)
- encoder output : variational distribution
decoder : latent variables의 input reconstruct
- **low validity** : often produce unnatural molecules or even invalid outputs
    
    이유 : multimodal이면 KL divergence 최소화로 불충분 & true posterior distribution은 주어진 prior로 잘 추정되지 않을 수도 있음.
    
- latent variables가 decoding되는 ‘latent space’ : wide region일수록 higher diversity & lower rebundancy

**GAN** : difficulty in handling discrete variables

- validity는 높아도 **diversity**가 낮음.
    
    **원인** : **discrete** (categorical) representation of atomic symbols로 표현되는 분자 구조 → train시킬 때 같은 instance가 반복 생성됨.
    
- **low uniqueness**

**ARAE**(Adversarially Regularized Autoencoder)

- latent variable models : discretized molecular structure inputs → continuous latent representation으로 변형
    
    encoder-decoder architecture (**encoder** : SMILES를 discrete random variable input(latent vectors)으로 변환 / **decoder** : reconstruct)
    
    - single **LSTM** encoder : sequential SMILES strings → latent vectors로 변형
- key distinct feature : GAN의 adversarial training을 latent variables의 distribution을 추정하는데 사용
    
    분자의 distribution을 ~~data space~~보다는 **continuous latent space**로 estimate하자!
    
- posterior distribution ← adversarial training. minimizing the 1-Wasserstein distance between true&generated latent variables

**validity, uniqueness, novelty 성능 측정 (QM9)**

- ARAE의 novelty가 비교적 낮은 이유 : low chemical diversity of QM9 dataset 때문 (limited number of heavy atoms → novel molecules 생성 기회 제한)

test the smoothness of the latent space ← interpolating between 2 vectors in the latent space

- metrics smoothly converged : GAN 문제 해결

**CARAE** : desired(targeted) properties에 따른 분자 생성

1. **encoder** : SMILES sequences → latent variables
2. **generator** : produce new samples by taking random variables
3. distributions of 2 variables → becomes similar by minimizing 1st, 2nd term + **gradient descent optimization**
- **predictor** network : estimate variational mutual information (VMI)
- training : **decoder** reconstructs input molecular structures & property information of input molecules
- inference : sample new molecules by tuning the latent vector & specifying the desired property
- variational mutual information minimization framework → manipulate latent variables + target properties
    - Molecules with desired(targeted) properties 장점
        - can be searched by advanced Bayesian optimization
            
            참고 : Bayesian graph convolutional network를 이용하여 EGFR → hit compounds의 de novo design에 사용
            
        - can directly incorporate target properties into the generation process to estimate a molecular distribution or manipulate a latent space
- single & multiple properties에 대해서도 동시 생성 잘함.
- target values(given designed points/properties)에 대해 각 latent space distribution이 localized(separated) → high accuracy of multiple property control
