{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install pandas\n",
        "!pip3 install scikit-learn\n",
        "!pip3 install rdkit\n",
        "!pip3 install torcheval"
      ],
      "metadata": {
        "id": "gRV19ZOdhfDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdchem\n",
        "from rdkit.Chem import AllChem\n",
        "import re\n",
        "\n",
        "\n",
        "Chiral = {\"CHI_UNSPECIFIED\":0,  \"CHI_TETRAHEDRAL_CW\":1, \"CHI_TETRAEDRAL_CCW\":2, \"CHI_OTHER\":3}\n",
        "Hybridization = {\"UNSPECIFIED\":0, \"S\":1, \"SP\":2, \"SP2\":3, \"SP3\":4, \"SP3D\":5, \"SP3D2\":6, \"OTHER\":7}\n",
        "\n",
        " # feature vector size\n",
        "atomInfo = 210\n",
        "structInfo = 21\n",
        "lensize= atomInfo + structInfo\n",
        "\n",
        "H_Vector = [0]*atomInfo\n",
        "H_Vector[0]= 1\n",
        "\n",
        "# 소문자 일치 판정\n",
        "lowerReg = re.compile(r'^[a-z]+$')\n",
        "def islower(s):\n",
        "    return lowerReg.match(s) is not None\n",
        "\n",
        "# 대문자 일치 판정\n",
        "upperReg = re.compile(r'^[A-Z]+$')\n",
        "def isupper(s):\n",
        "    return upperReg.match(s) is not None\n",
        "\n",
        "# atom 정보\n",
        "def calc_atom_feature(atom):\n",
        "\n",
        "    if atom.GetSymbol() == 'H':   feature = [1,0,0,0,0]\n",
        "    elif atom.GetSymbol() == 'C': feature = [0,1,0,0,0]\n",
        "    elif atom.GetSymbol() == 'O': feature = [0,0,1,0,0]\n",
        "    elif atom.GetSymbol() == 'N': feature = [0,0,0,1,0]\n",
        "    else: feature = [0,0,0,0,1]\n",
        "\n",
        "    feature.append(atom.GetTotalNumHs()/8)\n",
        "    feature.append(atom.GetTotalDegree()/4)\n",
        "    feature.append(atom.GetFormalCharge()/8)\n",
        "    feature.append(atom.GetTotalValence()/8)\n",
        "    feature.append(atom.IsInRing()*1)\n",
        "    feature.append(atom.GetIsAromatic()*1)\n",
        "\n",
        "    f =  [0]*(len(Chiral)-1)\n",
        "    if Chiral.get(str(atom.GetChiralTag()), 0) != 0:\n",
        "        f[Chiral.get(str(atom.GetChiralTag()), 0)] = 1\n",
        "    feature.extend(f)\n",
        "\n",
        "    f =  [0]*(len(Hybridization)-1)\n",
        "    if Hybridization.get(str(atom.GetHybridization()), 0) != 0:\n",
        "        f[Hybridization.get(str(atom.GetHybridization()), 0)] = 1\n",
        "    feature.extend(f)\n",
        "\n",
        "    return(feature)\n",
        "\n",
        "\n",
        "def calc_structure_feature(c,flag,label):\n",
        "    feature = [0]*structInfo\n",
        "\n",
        "    if c== '(' :\n",
        "        feature[0] = 1\n",
        "        flag = 0\n",
        "    elif c== ')' :\n",
        "        feature[1] = 1\n",
        "        flag = 0\n",
        "    elif c== '[' :\n",
        "        feature[2] = 1\n",
        "        flag = 0\n",
        "    elif c== ']' :\n",
        "        feature[3] = 1\n",
        "        flag = 0\n",
        "    elif c== '.' :\n",
        "        feature[4] = 1\n",
        "        flag = 0\n",
        "    elif c== ':' :\n",
        "        feature[5] = 1\n",
        "        flag = 0\n",
        "    elif c== '=' :\n",
        "        feature[6] = 1\n",
        "        flag = 0\n",
        "    elif c== '#' :\n",
        "        feature[7] = 1\n",
        "        flag = 0\n",
        "    elif c== '\\\\':\n",
        "        feature[8] = 1\n",
        "        flag = 0\n",
        "    elif c== '/' :\n",
        "        feature[9] = 1\n",
        "        flag = 0\n",
        "    elif c== '@' :\n",
        "        feature[10] = 1\n",
        "        flag = 0\n",
        "    elif c== '+' :\n",
        "        feature[11] = 1\n",
        "        flag = 1\n",
        "    elif c== '-' :\n",
        "        feature[12] = 1\n",
        "        flag = 1\n",
        "    elif c.isdigit() == True:\n",
        "        if flag == 0:\n",
        "            if c in label:\n",
        "                feature[20] = 1\n",
        "            else:\n",
        "                label.append(c)\n",
        "                feature[19] = 1\n",
        "        else:\n",
        "            feature[int(c)-1+12] = 1\n",
        "            flag = 0\n",
        "    return(feature,flag,label)\n",
        "\n",
        "\n",
        "def calc_featurevector(mol, smiles,atomsize):\n",
        "    flag = 0\n",
        "    label = []\n",
        "    molfeature=[]\n",
        "    idx = 0\n",
        "    j = 0\n",
        "\n",
        "    for c in smiles:\n",
        "        if islower(c) == True: continue\n",
        "        elif isupper(c) == True:\n",
        "            if c == 'H':\n",
        "                molfeature.extend(H_Vector)\n",
        "            else:\n",
        "                molfeature.extend(calc_atom_feature(rdchem.Mol.GetAtomWithIdx(mol, idx)))\n",
        "                idx = idx + 1\n",
        "            molfeature.extend([0]*structInfo)\n",
        "            j = j +1\n",
        "\n",
        "        else:\n",
        "            molfeature.extend([0]*atomInfo)\n",
        "            f,flag,label = calc_structure_feature(c,flag,label)\n",
        "            molfeature.extend(f)\n",
        "            j = j +1\n",
        "\n",
        "    # 0-Padding\n",
        "    molfeature.extend([0]*(atomsize-j)*lensize)\n",
        "    return(molfeature)\n",
        "\n",
        "\n",
        "def mol_to_feature(mol,n,atomsize):\n",
        "    try: defaultSMILES = Chem.MolToSmiles(mol, kekuleSmiles=False, isomericSmiles=True, rootedAtAtom=int(n))\n",
        "    except: defaultSMILES = Chem.MolToSmiles(mol, kekuleSmiles=False, isomericSmiles=True)\n",
        "    try: isomerSMILES = Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True, rootedAtAtom=int(n))\n",
        "    except: isomerSMILES = Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True)\n",
        "    return calc_featurevector(Chem.MolFromSmiles(defaultSMILES), isomerSMILES,atomsize)\n",
        "\n",
        "def mol_to_allSMILESfeature(mol, atomsize):\n",
        "    idx, features =0,  []\n",
        "    while idx < mol.GetNumAtoms():\n",
        "        try: defaultSMILES = Chem.MolToSmiles(mol, kekuleSmiles=False, isomericSmiles=True, rootedAtAtom=int(idx))\n",
        "        except: break\n",
        "        isomerSMILES = Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True, rootedAtAtom=int(idx))\n",
        "        features.append(calc_featurevector(Chem.MolFromSmiles(defaultSMILES), isomerSMILES,atomsize))\n",
        "        idx = idx + 1\n",
        "    return(features)\n",
        "\n",
        "#-------------------------------------------------------------\n",
        " # Sigmoid function definition\n",
        "def strong_sigmoid(x):\n",
        "    return 1*(x >=0)\n",
        "\n",
        "#-------------------------------------------------------------\n",
        " # detaset function definition\n",
        "def random_list(x, seed=0):\n",
        "    np.random.seed(seed)\n",
        "    np.random.shuffle(x)\n",
        "\n",
        "def data_boostDataset(P,N,boost=1,seed=0):\n",
        "    random_list(P,seed)\n",
        "    random_list(N,seed)\n",
        "    T = [0]*len(N)+ [1]*(len(P)*boost)\n",
        "    for i in range(boost):N.extend(P)\n",
        "    random_list(N,seed)\n",
        "    random_list(T,seed)\n",
        "    return N, T"
      ],
      "metadata": {
        "id": "tft2KzqQtDlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torcheval.metrics import BinaryAccuracy\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader # 학습 및 배치로 모델에 넣어주기 위한 툴\n",
        "\n",
        "#import torch.nn.init as init # 텐서에 초기값을 줌\n",
        "#import torchvision.datasets as datasets # 이미지 데이터셋 집합체\n",
        "#import torchvision.transforms as transforms # 이미지 변환 툴\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "trainset =\n",
        "testset =\n",
        "\n",
        "batch_size = 32\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class SCFPModel(nn.Module):\n",
        "    def __init__(self, atomsize, lensize, k1, s1, f1, k2, s2, k3, s3, f3, k4, s4, n_hid, n_out):\n",
        "\n",
        "        # atomsize, lenseize = size of feature matrix\n",
        "        # k1, s1, f1 = window-size, stride-step, No. of filters of first convolution layer\n",
        "        # k2, s2 = window-size, stride-step of first max-pooling layer\n",
        "        # k3, s3, f3 = window-size, stride-step, No. of filters of second convolution layer\n",
        "        # k4, s4 = window-size, stride-step of second max-pooling layer\n",
        "\n",
        "        super().__init__()\n",
        "        conv1 = nn.Conv2D(1, f1, (k1, lensize), stride=s1, pad = (k1//(2,0))),\n",
        "        bn1 = nn.BatchNorm2d(f1),\n",
        "        conv2 = nn.Conv2D(f1, f3, (k3, 1), stride=s3, pad = (k3//(2,0))),\n",
        "        bn2 = nn.BatchNorm2d(f3),\n",
        "        fc3 = nn.Linear(None, n_hid),\n",
        "        bn3 = nn.BatchNorm2d(n_hid),\n",
        "        fc4 = nn.Linear(None, n_out)\n",
        "\n",
        "        self.atomsize, self.lensize, self.n_out = atomsize, lensize, n_out\n",
        "        self.k1, self.s1, self.f1, self.k2, self.s2, self.k3, self.s3, self.f3, self.k4, self.s4 = k1, s1, f1, k2, s2, k3, s3, f3, k4, s4\n",
        "        self.l1 = (self.atomsize+(self.k1//2*2)-self.k1)//self.s1+1\n",
        "        self.l2 = (self.l1+(self.k2//2*2)-self.k2)//self.s2+1\n",
        "        self.l3 = (self.l2+(self.k3//2*2)-self.k3)//self.s3+1\n",
        "        self.l4 = (self.l3+(self.k4//2*2)-self.k4)//self.s4+1\n",
        "\n",
        "    def predict(self,x):\n",
        "        h = nn.LeakyReLU(self.bn1(self.conv1(x))) # 1st conv\n",
        "        h = nn.AvgPool2d(h, (self.k2,1), stride=self.s2, pad=(self.k2//(2,0))) # 1st pooling\n",
        "        h = nn.LeakyReLU(self.bn2(self.conv2(h))) # 2nd conv\n",
        "        h = nn.AvgPool2d(h, (self.k4,1), stride=self.s4, pad=(self.k4//(2,0))) # 2nd pooling\n",
        "        h = nn.MaxPool2d(h, (self.l4,1)) # grobal max pooling, fingerprint\n",
        "        h = self.fc3(h) # fully connected\n",
        "        sr = 0.00001* np.mean(np.log(1 + h.data * h.data)) # sparse regularization\n",
        "        h = nn.LeakyReLU(self.bn3(h))\n",
        "        return self.fc4(h), sr\n",
        "\n",
        "    def __call__(self, x, t):\n",
        "        y, sr = self.predict(x)\n",
        "        loss = nn.BCEWithLogitsLoss(y, t) + sr\n",
        "        accuracy = nn.BinaryAccuracy(y, t)\n",
        "        report({'loss': loss, 'accuracy': accuracy}, self)\n",
        "        return loss\n",
        "\n",
        "    def fingerprint(self,x):\n",
        "        x = Variable(x.astype(np.float32).reshape(-1,1, self.atomsize, self.lensize))\n",
        "        h = nn.LeakyReLU(self.bn1(self.conv1(x))) # 1st conv\n",
        "        h = nn.AvgPool2d(h, (self.k2,1), stride=self.s2, pad=(self.k2//(2,0))) # 1st pooling\n",
        "        h = nn.LeakyReLU(self.bn2(self.conv2(h))) # 2nd conv\n",
        "        h = nn.AvgPool2d(h, (self.k3,1), stride=self.s3, pad=(self.k3//(2,0))) # 2nd pooling\n",
        "        h = nn.MaxPool2d(h, (self.l4,1)) # grobal max pooling, fingerprint\n",
        "        return h.data\n",
        "\n",
        "    def layer1(self,x):\n",
        "        x = Variable(x.astype(np.float32).reshape(-1,1, self.atomsize, self.lensize))\n",
        "        h = self.bn1(self.conv1(x)) # 1st conv\n",
        "        return h.data\n",
        "\n",
        "    def pool1(self,x):\n",
        "        x = Variable(x.astype(np.float32).reshape(-1,1, self.atomsize, self.lensize))\n",
        "        h = nn.LeakyReLU(self.bn1(self.conv1(x))) # 1st conv\n",
        "        h = nn.AvgPool2d(h, (self.k2,1), stride=self.s2, pad=(self.k2//(2,0))) # 1st pooling\n",
        "        return h.data\n",
        "\n",
        "    def layer2(self,x):\n",
        "        x = Variable(x.astype(np.float32).reshape(-1,1, self.atomsize, self.lensize))\n",
        "        h = nn.LeakyReLU(self.bn1(self.conv1(x))) # 1st conv\n",
        "        h = nn.AvgPool2d(h, (self.k2,1), stride=self.s2, pad=(self.k2//(2,0))) # 1st pooling\n",
        "        h = self.bn2(self.conv2(h)) # 2nd conv\n",
        "        return h.data\n",
        "\n",
        "    def pool2(self,x):\n",
        "        x = Variable(x.astype(np.float32).reshape(-1,1, self.atomsize, self.lensize))\n",
        "        h = nn.LeakyReLU(self.bn1(self.conv1(x))) # 1st conv\n",
        "        h = nn.AvgPool2d(h, (self.k2,1), stride=self.s2, pad=(self.k2//(2,0))) # 1st pooling\n",
        "        h = nn.LeakyReLU(self.bn2(self.conv2(h))) # 2nd conv\n",
        "        h = nn.AvgPool2d(h, (self.k3,1), stride=self.s3, pad=(self.k3//(2,0))) # 2nd pooling\n",
        "        return h.data"
      ],
      "metadata": {
        "id": "UMsGybMHw2eF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "1e27d0b9-d88c-4624-d375-ddb694de1210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-89ed6af67a20>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SCFPModel()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "n_epochs = 300\n",
        "for epoch in range(n_epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "        # forward, backward, and then weight update\n",
        "        y_pred = model(inputs)\n",
        "        loss = loss_fn(y_pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    acc = 0\n",
        "    count = 0\n",
        "    for inputs, labels in testloader:\n",
        "        y_pred = model(inputs)\n",
        "        acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
        "        count += len(labels)\n",
        "    acc /= count\n",
        "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))\n",
        "\n",
        "torch.save(model.state_dict(), \"SCFPmodel.pth\")"
      ],
      "metadata": {
        "id": "ztCeDSmMs-AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pnVBJeo2r1aj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}