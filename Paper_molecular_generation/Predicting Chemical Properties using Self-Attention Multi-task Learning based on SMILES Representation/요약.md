# 요약

descriptors : 저차원 벡터로 encoding시킴. compute 가능.

fingerprints : 생성 이후 크기가 일정 길이의 비트 패턴으로 고정되는 분자 표현형. 단 결과 해석 시 추가 변환 과정이 필요하고, 특정 substructures의 search space 제한.

⇒ **SMILES를 input으로 사용하여 embedding vectors 학습**(descriptor-free, computation 불필요) → **SA**

**pretraining : SMILES 만드는 과정**

**CNN** : multi-task learning 환경에서 sharing multiple tasks를 통해 feature 학습 도움.

FP2VEC : multi-task learning (SA module없는 SA-MTL)

**Transformer** : long-range dependency 학습과 병렬 computation 가능.

**Encoder**(SMILES 표현 - hidden layer에 사용) + **Decoder**(target인 canonical SMILES 생성)

**SA** : **encoder** 역할로서 classification predictor. descriptors&fingerprints compute하지 않고 SMILES를 input으로 사용. long-range dependency 학습.

- 원래 SA module은 multi-layered 구조 → recurrent
- **multi-task learning** 환경에서 SA module은 multiple tasks의 shared factors를 학습하는데 불충분 (+ imbalanced data) => CNN 필요
    
    multi-task learning : shared hidden layers & discrete output layers
    
    **shared hidden layer : representation learning** 통해 features 추출하는 **fingerprint** 역할. features를 공유하여 multiple task resemblance 수행
    
    → 이후 FC layer에 적용해 predict
    

**SA-MTL for compound property classification**

- character embedding : 원자마다 atom-embedding vector index 할당. two-character atoms 고려.
- CNN layer : shared hidden layer.( multiple tasks 공유 통해 multi-task learning 환경에서 feature 학습)
- SA module : encoder만 포함, multi-head structure에도 적용. hyperparameter optimization 이후에 7-layered SA 사용.
- Discrete output layer : (balancing bias 적용한 FC layer) 2번 구현하여 final prediction layer로서 사용. balancing bias를 output layer의 가중치로 적용하여 클래스 불균형 문제 완화.

**성능에 중요한 요소**

- two-character atoms의 분배
- multi-task learning
- CNN layer → Additional data + 목적 함수의 명시적 피드백으로 성능 향상 가능

---

### Introduction & Conclusion

**QSAR 모델 성능이 Molecular descriptors & fingerprints에 의존적**

- descriptors 역할 : low-dimensional vectors로 encode
    
    cheminformatics library & SMILES로 compute 가능
    
- molecular-structural features 선택 → 고정 길이의 string/vector로 encoding (생성 이후 크기 고정)
- Fingerprint : 각 분자의 특성을 **일정 길이**의 비트 패턴(숫자)으로 표현 → **크기가 일정한 분자 표현형**! 
(주변 원자들과의 연결 정보를 반복적으로 추가하며 특성 업데이트)
    - Fingerprint 기반 DL 모델들의 문제점
        - SMILES input이 fingerprint로 변형됨 : train 결과를 해석할 때 추가 변환 과정 필요
        - fingerprints로 변환되는 특정 substructures의 search space가 제한되거나 무시됨 (다른 원자 환경이 같은 bit로 매핑)

⇒ **SMILES를 input으로** 사용하여 각 character notation을 변환시킨 **embedding vectors 학습 ⇒ “descriptor-free”**

embedding vectors는 데이터셋에 따라 fine-tuning 가능

**Transformer과 Multi-head SA → Transformer의 encoder을 classification predictor로 제시**

- Transformer 장점 : input data에서 long-range dependency 학습 가능 + recurrent connection이 없어서 병렬 computation 가능
- **SA-based model** : descriptors와 fingerprint를 compute하지 않고 SMILES를 input으로 사용!

**SA module의 representation learning 성능을 multi-task learning 환경 + Imbalanced chemical datasets에서 평가**

**Multi-task learning**도 포함

- Multi-task learning 장점
    - training samples의 generalization & implicit augmentation
    - overfitting의 위험 감소 : 다양한 tasks는 다른 양의 noise 가짐.
    - shared hidden layers가 중요하고 고유한(내재된) **features(representation learning)**에 집중하도록 할 수 있음.
- **shared hidden** layers : **representation learning 수행 + multiple task resemblance**
    
    representation learning을 통해 자동으로 유용한 정보 추출(underlying subset을 capture)
    
    tasks 사이에 여러 features를 공유하여 input data&tasks를 다른 tasks와 유사하도록
    
- **discrete output** layers

> **SA-MTL을 QSAR 모델로 제안**
> 

### Related work

Dataset : Tox21 + HIV/SIDER/BBBP/clintox

→ 작은 size & class-imbalanced dataset 고려 (CNN)

- **SCFP & FP2VEC**
    
    SMILES sequence로 SMILES feature matrix compute / FP2VEC는 lookup table의 randomized vector로 embedding
    
    둘다 molecular fingerprint 대체 가능 / CNN layers 중 일부는 충분한 학습 능력
    
    - SCFP : custom word embedding으로 embedding layer을 SMILES에 추가하는 방법 제안 (Tox21 data에만 집중 + pre-processing data)
    - FP2VEC : **multi-task learning**
- **Smiles_Transformer : encoder&decoder 구조**
    
    unsupervised learning으로 transformer model을 pre-training에만 사용. **simple predictor** model 사용
    
    **Encoder(SMILES 표현) + Decoder target(canonical SMILES**. SMILES-Enumerator로 target SMILES 생성)
    
    - pre-training 이후에는 **encoder에 의해 생성된 hidden layer을 molecular fingerprint로서** 사용 → **FC layer**에 적용해 predict
- **Transformer-CNN : CNN layers 위치**
    
    Smiles_Transformer과 다르게 **encoder(SA module)만** 사용. two-character atoms 위해 더 복잡한 **predictor** 사용.
    
    - SA module은 long-range dependency 학습 가능(CNN은 작은 filter size에 의해 정의)
    
    **SA module(long-range relationship 관리) 이후에 CNN layer(unit learning)**
    
- **BiLSTM-SA**
    
    **BiLSTM**(RNN 변형) + **수정된 SA module** + **Dense** layer
    
    **prediction** 단계에서 attention module 사용하여 훈련 모델 분석. **~~two-characters atom~~** 언급 X
    

### SA-MTL model

compound property classification - CNN layer, SA module, discrete output layer로 구성

multi-task learning, two-character atoms 고려.

- SMILES processing : **character embedding** → 분석을 위해 embedding vectors 저장해야!
    
    characters로 구성된 원자에 atom-embedding vector index 할당. 수소 원자를 bond signal로 취급하기도 한다.
    
- **CNN layer : shared hidden layer**
    
    2차원 convolution / filter size : 7 / output : [batch size, sequence size, hidden size]
    
    추가하면 multi-task learning 환경에서 sharing multiple tasks를 통해 feature 학습 도움.
    
- **SA module** : **encoder만** 포함하며 position embedding 없애도 됨. multi-head structure에도 적용.
    
    output : [batch size, sequence size, hidden size]
    
     hyperparameter optimization 이후에 **7-layered SA** 사용
    
- **Discrete output layer** : 2개의 **FC** layers로 구성
    
    FC layer은 single/multi 여부에 변하지 않고 output size는 FC layers를 모두 1로 설정
    
    max-pooling 같은 representation 차원 축소 방법보다 SA-MTL 구조가 효과적. 
    
    다른 transformer-variant model은 **final prediction layer**로서 dense/FC layer 사용
    
    **→ (Balancing bias를 적용한 FC layer ) x 2**
    
    balancing bias를 output layer의 가중치로 적용하여 클래스 불균형 문제 완화. (weighted cross-entropy function)
    

### 다른 model과 비교

- Smiles_Transformer
    - pre-training : large unlabeled data로부터 atom-level embedding 학습. SMILES 구현하려면 **protein** targets도 고려돼야 한다!
    - simple predictor model 사용 : pre-train의 중간 결과를 기반으로 dataset **fine-tune**에 사용.
- Transformer-CNN
    - two-character atoms에 더 복잡한 predictor 사용
    - **~~multi-task learning scheme~~** 미구현
- BiLSTM-SA
    - CNN 대신 BiLSTM(RNN)을 첫번째 구성 요소로 사용 → recurrent 구조라 computational speed 안 좋음.
    - SA module이 반복되지 않는다.
    - multi-task learning 미구현
    - **~~two-character atoms~~** 없음.

### Experiment & Result

- Tox21, HIV, CLINTOX에서 positive-negative ratio가 매우 **imbalanced**
- 검증 데이터에 대해 **AUC를 최대화**할 수 있는 model hyperparameters를 선택 → **최적화**
    
    random search → optimal hyperparameter 선택
    
    각 **검증** 데이터의 model **weights**는 저장 + **test** 데이터에서 모델을 사용하여 예측 성능 측정(**5번동안 반복된 평가의 평균**)
    
    **Performance metric : ROC-AUC**
    
- Tensorflow 2.1 ver. / Nvidia Titan RTX GPU 환경에서 수행

**TOX 21**

- compound instance가 multiple class들로 태그될 수 있음 → **multi-task learning**
- **1st evaluation :** train & test data with random split
- **2nd evaluation :** score data **- ensemble**
    
    **DeepTox**(TOX 21 Challenge 우승 모델) : **여러 다른 모델들의 ensemble** 기법 사용. 하나의 SA-MLT 모델의 여러 결과 사용.
    
    **우리 ensemble method : 같은 모델의 5 output probabilities 합침. (초기 가중치는 다르게 결정될 수 있음)**
    
    → DeepTox & SCFP와 비교하면 “score” data에서 더 나은 성능
    

**SIDER**

- ADR
- TOX21과 유사하게 compound instance는 multiple class들로 태그될 수 있음. → **multi-task learning**
- 적은 data instances & 많은 class임에도 불구하고 Tox21 dataset과 비교하여 좋은 성능 보여줌.

**HIV**

- **ligand의 SMILES만 input으로** 제공되기 때문에 성능 제한 존재.
    
    Transformer_CNN과 비교하여 AUC 감소
    
- **scaffold** splitting - 구조적으로 다른 분자들을 다른 train/test subset으로 분리 ⇒ 얻은 결과는 따로 분리

**BBBP & clintox**

- **BBBP** : **scaffold** split method 적용하여 SA-MTL 평가. filtering out 과정 거침.
    
    0.966 AUC score과 같이 높은 score 원인 : **positive to negative ratio**
    
- **CLINTOX :** FDA-승인 drugs list + 독성 가진 drugs list를 사용하여 dataset compile

⇒ **두 dataset 모두 그렇게 중요하지 않은 noise 포함 + 목적이 ML 예측에 적합**

**Ablation study**

- SA-MTL의 여러 **features**의 효율성 평가. (best performing model부터 시작해 개별적으로 features **제거해나감. → 성능의 변화 추적**)
    
    Tox21 dataset의 5번 모델 테스트의 평균
    
- **two-character embedding / SA / multi-task learning / CNN layer**
    - character embedding assign (two-character atoms)
        
        character embedding model이 **테스트** 데이터에 대해서는 시간에 따라 0.87까지 **내려감**. → two-character atoms의 random 분배 때문
        
    - SA module + multi-task learning scheme 필수
    - discrete output layer을 max-pooling layer로 대체하면 성능 향상
        
        ⇒ simple model + imbalanced data에서는 더 나은 성능
        
        > 차원 축소 단계동안 ~~정보 손실~~의 가능성 있는 **layer 선택** : SA module같은 복잡한 요소에 중요한 영향!
        > 
    - CNN layer 없이 평가했더니 안 좋은 결과
        
        multi-task learning 환경에서 SA module은 multiple tasks의 shared factors를 학습하는데 불충분 (+ imbalanced data)
        
        > **Additional** **data + 목적 함수로부터 더 명시적 피드백** → 성능 향상!
        > 
- **CNN layer / discrete output layer**
    - CNN을 RNN(gated-recurrent unit)으로 대체해봤더니 속도 느림.
    - **final layer에서** discrete output layer 대신 max-pooling layer 사용하여 평가
        
        max-pooling은 simple model에서 좋은 성능, discrete output layer이 더 좋은 성능
        
- **multi-head feature / position encoding** (5 multi-heads & position encoding)
    - multi-head feature은 화합물 예측에 중요 영향 끼치지 않는다. **classification에 효율적이지 않다**.
        
        multiple different position 기반 정보로 수정
        
        → **over-parametrization issue** (SA heads는 사소한 정보를 포함하거나 가끔 같은 위치에 - redundancy)
        
    - 각 원자에 position embedding value를 추가해도 모델 성능은 같게 유지
        
        원자의 position은 문법적 의미를 뜻하지 않기 때문에 자연어 문장과 SMILES string는 다름
        
        target 문장과 같은 feedback 없이 classification dataset에 적용 → position embedding은 성능에 제한된 영향